{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"data\"\n",
    "\n",
    "def read_patient_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep=\",\")\n",
    "    return df\n",
    "\n",
    "# Process each patient file\n",
    "def process_patient_data(patient_file):\n",
    "    df = read_patient_data(patient_file)\n",
    "\n",
    "    df['Time'] = pd.to_timedelta(df['Time'] + ':00')\n",
    "    df['Time'] = df['Time'].dt.ceil('h')\n",
    "    df['Time'] = df['Time'].dt.total_seconds() // 3600\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_parquet(letter:str, keepICUType=False):\n",
    "\n",
    "    folder_path = \"data/set-\" + letter\n",
    "    static_columns = [\"RecordID\", \"Age\", \"Gender\", \"Height\", \"ICUType\", \"Weight\"] #ICU-Type can be dropped later\n",
    "    df_processed = pd.DataFrame()\n",
    "\n",
    "    for file_name in tqdm(os.listdir(folder_path)):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = process_patient_data(file_path)\n",
    "        df = df.pivot_table(index=\"Time\", columns=\"Parameter\", values=\"Value\", aggfunc=\"last\").reset_index()\n",
    "        df = df.reindex(columns= [\"Time\"] + static_columns + [col for col in df.columns if col not in static_columns + [\"Time\"]])\n",
    "        df.set_index('Time', inplace=True)\n",
    "        df = df.reindex(range(49), fill_value=np.nan)\n",
    "        df[static_columns] = df[static_columns].ffill().bfill()\n",
    "        df.reset_index(drop=False, inplace=True)\n",
    "        df_processed = pd.concat([df_processed, df], ignore_index=True)\n",
    "\n",
    "    if not keepICUType:\n",
    "        df_processed = df_processed.drop(columns=[\"ICUType\"])\n",
    "\n",
    "    df_processed.to_parquet(f\"data_{letter}.parquet\", engine=\"pyarrow\", index=False)\n",
    "\n",
    "    return df_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:19<00:00, 203.25it/s]\n",
      "100%|██████████| 4000/4000 [00:19<00:00, 205.38it/s]\n",
      "100%|██████████| 4000/4000 [00:19<00:00, 203.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for letter in [\"a\", \"b\", \"c\"]:\n",
    "    generate_parquet(letter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data_b.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196000, 42)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fglök"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
