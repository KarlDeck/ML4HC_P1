{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:50px\"><strong>ML4HC Project 1 - Task 4</strong></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"../ml4h_data/p1/\"#\"data\"\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Prompting an LLM to solve a time-series problem - Q4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# Example of running a model in Ollama with a properly formatted message\n",
    "response = ollama.chat(\n",
    "    \"llama3.2\", \n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, Ollama! How are you?\"}]\n",
    ")\n",
    "\n",
    "# Output the response\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from ollama import Client\n",
    "\n",
    "# Initialize Ollama client\n",
    "client = Client()\n",
    "\n",
    "def create_patient_summaries(df):\n",
    "    summaries = {}\n",
    "    grouped = df.groupby(\"RecordID\")\n",
    "    for rid, group in grouped:\n",
    "        features = []\n",
    "        for var in group[\"Variable\"].unique():\n",
    "            vals = group[group[\"Variable\"] == var][\"Value\"]\n",
    "            if not vals.empty:\n",
    "                stats = f\"{var}: min={vals.min():.2f}, max={vals.max():.2f}, mean={vals.mean():.2f}\"\n",
    "                features.append(stats)\n",
    "        text = f\"Patient {rid} summary: \" + \", \".join(features)\n",
    "        summaries[rid] = text\n",
    "    return summaries\n",
    "\n",
    "# LLM prompt with chain-of-thought and prediction at the end\n",
    "def query_llm(prompt):\n",
    "    response = client.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    prompt +\n",
    "                    \"\\nBased on the above medical features, reason step-by-step using medical knowledge \"\n",
    "                    \"to determine whether the patient will die in hospital but never print your reasoning . The only thing you should return is only one word: Yes or No.\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"].strip()\n",
    "\n",
    "def predict_with_llm(summaries, max_patients=None):\n",
    "    predictions = {}\n",
    "    for i, (rid, text) in enumerate(tqdm(summaries.items())):\n",
    "        if max_patients and i >= max_patients:\n",
    "            break\n",
    "        full_response = query_llm(text)\n",
    "        final_word = full_response.strip().split()[-1].lower()\n",
    "\n",
    "        if final_word == \"yes\" or final_word == \"yes.\":\n",
    "            pred = 1\n",
    "        elif final_word == \"no\" or final_word == \"no.\":\n",
    "            pred = 0\n",
    "        else:\n",
    "            pred = None\n",
    "\n",
    "        predictions[rid] = pred\n",
    "        print(f\"\\nRecordID: {rid}\")\n",
    "        print(full_response)\n",
    "        print(f\"→ Prediction: {pred}\\n\")\n",
    "    return predictions\n",
    "\n",
    "def evaluate_predictions(preds, y_true):\n",
    "    valid = {rid: pred for rid, pred in preds.items() if pred is not None}\n",
    "    y_pred = [valid[rid] for rid in y_true.index if rid in valid]\n",
    "    y_true_vals = [y_true[rid] for rid in y_true.index if rid in valid]\n",
    "\n",
    "    auroc = roc_auc_score(y_true_vals, y_pred)\n",
    "    auprc = average_precision_score(y_true_vals, y_pred)\n",
    "    print(f\"LLM AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data_c_scaled_nonImputed.parquet\")\n",
    "df = df.melt(id_vars=[\"RecordID\", \"Time\"], var_name=\"Variable\", value_name=\"Value\")\n",
    "\n",
    "# Find RecordIDs where in-hospital death == 1\n",
    "positive_ids = df[(df[\"Variable\"] == \"In-hospital_death\") & (df[\"Value\"] == 1)][\"RecordID\"].unique()\n",
    "\n",
    "# Filter df to only those records\n",
    "df = df[df[\"RecordID\"].isin(positive_ids)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "y_true = df[df[\"Variable\"] == \"In-hospital_death\"].groupby(\"RecordID\")[\"Value\"].first()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/585 [00:04<44:01,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RecordID: 152873.0\n",
      "No.\n",
      "→ Prediction: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/585 [00:06<31:01,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RecordID: 152893.0\n",
      "No.\n",
      "→ Prediction: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/585 [00:08<26:26,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RecordID: 152914.0\n",
      "No\n",
      "→ Prediction: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/585 [00:10<23:35,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RecordID: 152938.0\n",
      "No.\n",
      "→ Prediction: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/585 [00:13<25:28,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RecordID: 152956.0\n",
      "No\n",
      "→ Prediction: 0\n",
      "\n",
      "LLM AUROC: nan, AUPRC: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/homebrew/anaconda3/envs/ml4hc/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predssummaries = create_patient_summaries(df)\n",
    "preds = predict_with_llm(summaries, max_patients=5)\n",
    "evaluate_predictions(preds, y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Using LLMs to retrieve embeddings - Q4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Using time-series foundation models - Q4.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4hc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
